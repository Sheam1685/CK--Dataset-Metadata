{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ckplus_dataset = pd.read_csv(\"dataset/ckplus_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emotion_features(emotion):\n",
    "    distance_features = []\n",
    "    angle_features = []\n",
    "    with open(f\"features/{emotion}.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            feature = line.strip().split()\n",
    "            feature = [int(value) for value in feature[0][2:-1].split(\",\")]\n",
    "            if len(feature) == 2:\n",
    "                distance_features.append(feature)\n",
    "            else:\n",
    "                angle_features.append(feature)\n",
    "    return distance_features, angle_features\n",
    "\n",
    "\n",
    "def load_emotion_features():\n",
    "    emotions = [\"neutral\", \"anger\", \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\"]\n",
    "    emotion_features = {}\n",
    "    for emotion in emotions:\n",
    "        distance_features, angle_features = read_emotion_features(emotion)\n",
    "        emotion_features[emotion] = (distance_features, angle_features)\n",
    "    return emotion_features\n",
    "\n",
    "\n",
    "emotion_features = load_emotion_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
    "\n",
    "\n",
    "def smaller_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    return np.arccos(cosine) * 180 / np.pi\n",
    "\n",
    "\n",
    "def mid_point(a, b):\n",
    "    return [(a[0] + b[0]) / 2, (a[1] + b[1]) / 2]\n",
    "\n",
    "\n",
    "def get_face_width(data):\n",
    "    point1 = data[\"landmark_2\"].split(\" \")\n",
    "    point1 = [float(point1[0]), float(point1[1])]\n",
    "    point2 = data[\"landmark_16\"].split(\" \")\n",
    "    point2 = [float(point2[0]), float(point2[1])]\n",
    "    return euclidean_distance(point1, point2)\n",
    "\n",
    "\n",
    "def generate_distance_features(data, feature_emotion):\n",
    "    distance_features_template = emotion_features[feature_emotion][0]\n",
    "\n",
    "    distance_features = []\n",
    "    for feature in distance_features_template:\n",
    "        point1 = data[f\"landmark_{feature[0]}\"].split(\" \")\n",
    "        point1 = [float(point1[0]), float(point1[1])]\n",
    "        point2 = data[f\"landmark_{feature[1]}\"].split(\" \")\n",
    "        point2 = [float(point2[0]), float(point2[1])]\n",
    "\n",
    "        distance = euclidean_distance(point1, point2)\n",
    "        distance_features.append(distance)\n",
    "\n",
    "    if feature_emotion == \"neutral\":\n",
    "        point1 = data[\"landmark_37\"].split(\" \")\n",
    "        point1 = [float(point1[0]), float(point1[1])]\n",
    "        point2 = data[\"landmark_46\"].split(\" \")\n",
    "        point2 = [float(point2[0]), float(point2[1])]\n",
    "        point3 = data[\"landmark_9\"].split(\" \")\n",
    "        point3 = [float(point3[0]), float(point3[1])]\n",
    "\n",
    "        distance = euclidean_distance(mid_point(point1, point2), point3)\n",
    "        distance_features.append(distance)\n",
    "\n",
    "    distance_features = np.array(distance_features)\n",
    "    distance_features = distance_features / get_face_width(data)\n",
    "\n",
    "    return distance_features\n",
    "\n",
    "\n",
    "def generate_angle_features(data, feature_emotion):\n",
    "    angle_features_template = emotion_features[feature_emotion][1]\n",
    "\n",
    "    angle_features = []\n",
    "    for feature in angle_features_template:\n",
    "        point1 = data[f\"landmark_{feature[0]}\"].split(\" \")\n",
    "        point1 = [float(point1[0]), float(point1[1])]\n",
    "        point2 = data[f\"landmark_{feature[1]}\"].split(\" \")\n",
    "        point2 = [float(point2[0]), float(point2[1])]\n",
    "        point3 = data[f\"landmark_{feature[2]}\"].split(\" \")\n",
    "        point3 = [float(point3[0]), float(point3[1])]\n",
    "\n",
    "        angle = smaller_angle(point1, point2, point3)\n",
    "        angle_features.append(angle)\n",
    "\n",
    "    angle_features = np.array(angle_features)\n",
    "    angle_features = angle_features / 180\n",
    "\n",
    "    return angle_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data, feature_emotion, feature_type):\n",
    "    features = np.array([])\n",
    "\n",
    "    if feature_type == \"distance\" or feature_type == \"both\":\n",
    "        distance_features = generate_distance_features(data, feature_emotion)\n",
    "        features = np.concatenate((features, distance_features))\n",
    "\n",
    "    if feature_type == \"angle\" or feature_type == \"both\":\n",
    "        angle_features = generate_angle_features(data, feature_emotion)\n",
    "        features = np.concatenate((features, angle_features))\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def generate_features_multiple(data, feature_emotions, feature_type):\n",
    "    all_features = np.array([])\n",
    "    \n",
    "    for feature_emotion in feature_emotions:\n",
    "        features = generate_features(data, feature_emotion, feature_type)\n",
    "        all_features = np.concatenate((all_features, features))\n",
    "        \n",
    "    return all_features\n",
    "\n",
    "\n",
    "def get_features_from_df(df, feature_emotions, feature_type):\n",
    "    features = []\n",
    "    for index, row in df.iterrows():\n",
    "        features.append(generate_features_multiple(row, feature_emotions, feature_type))\n",
    "\n",
    "    features = np.array(features)\n",
    "    print(features.shape)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def get_classes_from_df(df):\n",
    "    classes = []\n",
    "    for index, row in df.iterrows():\n",
    "        classes.append(row[\"subject_id\"])\n",
    "    return np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_type):\n",
    "    if model_type == \"lda\":\n",
    "        return LinearDiscriminantAnalysis()\n",
    "    elif model_type == \"svc\":\n",
    "        return SVC()\n",
    "    elif model_type == \"rand_forest\":\n",
    "        return RandomForestClassifier()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, X_test, y_test):\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_session_data(subject_id, session_id):\n",
    "    return df_ckplus_dataset[\n",
    "        (df_ckplus_dataset[\"subject_id\"] == subject_id)\n",
    "        & (df_ckplus_dataset[\"session_id\"] == session_id)\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_subjects(emotion, no_of_subjects=None):\n",
    "    df_subjects = pd.read_csv(f\"dataset/{emotion}_filtered.csv\")\n",
    "    if no_of_subjects is not None:\n",
    "        df_subjects = df_subjects.head(no_of_subjects)\n",
    "    assert no_of_subjects is None or len(df_subjects) == no_of_subjects\n",
    "    df_subjects = df_subjects[[\"subject_id\", \"session_id\"]]\n",
    "    \n",
    "    return df_subjects\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_data(emotion, no_of_subjects=None, seed=42):\n",
    "    subjects = get_subjects(emotion=emotion, no_of_subjects=no_of_subjects)\n",
    "\n",
    "    df_neutral_train = pd.DataFrame()\n",
    "    df_neutral_test = pd.DataFrame()\n",
    "    df_emotion_train = pd.DataFrame()\n",
    "    df_emotion_test = pd.DataFrame()\n",
    "\n",
    "    for index, row in subjects.iterrows():\n",
    "        subject_id = row[\"subject_id\"]\n",
    "        session_id = row[\"session_id\"]\n",
    "        subject_data = get_subject_session_data(subject_id, session_id)\n",
    "\n",
    "        neutral_data = subject_data.head(len(subject_data) // 2)\n",
    "        emotion_data = subject_data.tail(len(subject_data) // 2)\n",
    "        \n",
    "        neutral_data = neutral_data.sample(n=3, random_state=seed)\n",
    "        emotion_data = emotion_data.sample(n=3, random_state=seed)\n",
    "\n",
    "        neutral_train = neutral_data.head(2)\n",
    "        neutral_test = neutral_data.tail(1)\n",
    "        \n",
    "        emotion_train = emotion_data.head(2)\n",
    "        emotion_test = emotion_data.tail(1)\n",
    "        \n",
    "        df_neutral_train = pd.concat([df_neutral_train, neutral_train])\n",
    "        df_neutral_test = pd.concat([df_neutral_test, neutral_test])\n",
    "        \n",
    "        df_emotion_train = pd.concat([df_emotion_train, emotion_train])\n",
    "        df_emotion_test = pd.concat([df_emotion_test, emotion_test])\n",
    "        \n",
    "    return df_neutral_train, df_neutral_test, df_emotion_train, df_emotion_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(df_train, df_test, feature_emotions, feature_type, model_type):\n",
    "    X_train = get_features_from_df(df_train, feature_emotions, feature_type)\n",
    "    y_train = get_classes_from_df(df_train)\n",
    "\n",
    "    X_test = get_features_from_df(df_test, feature_emotions, feature_type)\n",
    "    y_test = get_classes_from_df(df_test)\n",
    "\n",
    "    model = get_model(model_type)\n",
    "    model = train_model(model, X_train, y_train)\n",
    "\n",
    "    return test_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neutral_train, df_neutral_test, df_emotion_train, df_emotion_test = generate_train_test_data(\"anger\", seed=55)\n",
    "\n",
    "df_combined_train = pd.concat([df_neutral_train, df_emotion_train])\n",
    "df_combined_test = pd.concat([df_neutral_test, df_emotion_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 9)\n",
      "(58, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9827586206896551"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_performance(\n",
    "    df_neutral_train, df_neutral_test, [\"neutral\"], \"distance\", \"rand_forest\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ckplus_dataset = pd.read_csv(\"dataset/ckplus_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emotion_features(emotion):\n",
    "    distance_features = []\n",
    "    angle_features = []\n",
    "    with open(f\"features/{emotion}.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            feature = line.strip().split()\n",
    "            feature = [int(value) for value in feature[0][2:-1].split(\",\")]\n",
    "            if len(feature) == 2:\n",
    "                distance_features.append(feature)\n",
    "            else:\n",
    "                angle_features.append(feature)\n",
    "    return distance_features, angle_features\n",
    "\n",
    "\n",
    "def load_emotion_features():\n",
    "    emotions = [\"neutral\", \"anger\", \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\", \n",
    "                \"neutral-anger\", \"neutral-disgust\", \"neutral-fear\", \"neutral-happiness\", \"neutral-sadness\", \"neutral-surprise\",\n",
    "                ]\n",
    "    emotion_features = {}\n",
    "    for emotion in emotions:\n",
    "        distance_features, angle_features = read_emotion_features(emotion)\n",
    "        emotion_features[emotion] = (distance_features, angle_features)\n",
    "    return emotion_features\n",
    "\n",
    "\n",
    "emotion_features = load_emotion_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
    "\n",
    "\n",
    "def smaller_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    return np.arccos(cosine) * 180 / np.pi\n",
    "\n",
    "\n",
    "def mid_point(a, b):\n",
    "    return [(a[0] + b[0]) / 2, (a[1] + b[1]) / 2]\n",
    "\n",
    "\n",
    "def get_face_width(data):\n",
    "    point1 = data[\"landmark_2\"].split(\" \")\n",
    "    point1 = [float(point1[0]), float(point1[1])]\n",
    "    point2 = data[\"landmark_16\"].split(\" \")\n",
    "    point2 = [float(point2[0]), float(point2[1])]\n",
    "    return euclidean_distance(point1, point2)\n",
    "\n",
    "\n",
    "def generate_distance_features(data, feature_emotion):\n",
    "    # print(\"feature_emotion\", feature_emotion)\n",
    "    distance_features_template = emotion_features[feature_emotion][0]\n",
    "\n",
    "    distance_features = []\n",
    "    for feature in distance_features_template:\n",
    "        point1 = data[f\"landmark_{feature[0]}\"].split(\" \")\n",
    "        point1 = [float(point1[0]), float(point1[1])]\n",
    "        point2 = data[f\"landmark_{feature[1]}\"].split(\" \")\n",
    "        point2 = [float(point2[0]), float(point2[1])]\n",
    "\n",
    "        distance = euclidean_distance(point1, point2)\n",
    "        distance_features.append(distance)\n",
    "\n",
    "    if feature_emotion == \"neutral\":\n",
    "        point1 = data[\"landmark_37\"].split(\" \")\n",
    "        point1 = [float(point1[0]), float(point1[1])]\n",
    "        point2 = data[\"landmark_46\"].split(\" \")\n",
    "        point2 = [float(point2[0]), float(point2[1])]\n",
    "        point3 = data[\"landmark_9\"].split(\" \")\n",
    "        point3 = [float(point3[0]), float(point3[1])]\n",
    "\n",
    "        distance = euclidean_distance(mid_point(point1, point2), point3)\n",
    "        distance_features.append(distance)\n",
    "\n",
    "    distance_features = np.array(distance_features)\n",
    "    distance_features = distance_features / get_face_width(data)\n",
    "\n",
    "    return distance_features\n",
    "\n",
    "\n",
    "def generate_angle_features(data, feature_emotion):\n",
    "    angle_features_template = emotion_features[feature_emotion][1]\n",
    "\n",
    "    angle_features = []\n",
    "    for feature in angle_features_template:\n",
    "        point1 = data[f\"landmark_{feature[0]}\"].split(\" \")\n",
    "        point1 = [float(point1[0]), float(point1[1])]\n",
    "        point2 = data[f\"landmark_{feature[1]}\"].split(\" \")\n",
    "        point2 = [float(point2[0]), float(point2[1])]\n",
    "        point3 = data[f\"landmark_{feature[2]}\"].split(\" \")\n",
    "        point3 = [float(point3[0]), float(point3[1])]\n",
    "\n",
    "        angle = smaller_angle(point1, point2, point3)\n",
    "        angle_features.append(angle)\n",
    "\n",
    "    angle_features = np.array(angle_features)\n",
    "    angle_features = angle_features / 180\n",
    "\n",
    "    return angle_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data, feature_emotion, feature_type):\n",
    "    features = np.array([])\n",
    "\n",
    "    if feature_type == \"distance\" or feature_type == \"both\":\n",
    "        distance_features = generate_distance_features(data, feature_emotion)\n",
    "        features = np.concatenate((features, distance_features))\n",
    "\n",
    "    if feature_type == \"angle\" or feature_type == \"both\":\n",
    "        angle_features = generate_angle_features(data, feature_emotion)\n",
    "        features = np.concatenate((features, angle_features))\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def generate_features_multiple(data, feature_emotions, feature_type):\n",
    "    all_features = np.array([])\n",
    "    \n",
    "    for feature_emotion in feature_emotions:\n",
    "        features = generate_features(data, feature_emotion, feature_type)\n",
    "        all_features = np.concatenate((all_features, features))\n",
    "        \n",
    "    return all_features\n",
    "\n",
    "\n",
    "def get_features_from_df(df, feature_emotions, feature_type):\n",
    "    features = []\n",
    "    for index, row in df.iterrows():\n",
    "        features.append(generate_features_multiple(row, feature_emotions, feature_type))\n",
    "\n",
    "    features = np.array(features)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def get_classes_from_df(df):\n",
    "    classes = []\n",
    "    for index, row in df.iterrows():\n",
    "        classes.append(row[\"subject_id\"])\n",
    "    return np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    Perceptron,\n",
    "    RidgeClassifier,\n",
    "    SGDClassifier,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_type, seed):\n",
    "    if model_type == \"LinearDiscriminantAnalysis\":\n",
    "        return LinearDiscriminantAnalysis()\n",
    "\n",
    "    if model_type == \"QuadraticDiscriminantAnalysis\":\n",
    "        # QuadraticDiscriminantAnalysis\n",
    "        return QuadraticDiscriminantAnalysis()\n",
    "\n",
    "    if model_type == \"LinearSVC\":\n",
    "        # LinearSVC\n",
    "        return LinearSVC(random_state=seed)\n",
    "\n",
    "    if model_type == \"NuSVC\":\n",
    "        # NuSVC\n",
    "        return NuSVC(random_state=seed)\n",
    "\n",
    "    if model_type == \"SVC\":\n",
    "        # SVC\n",
    "        return SVC(random_state=seed)\n",
    "\n",
    "    if model_type == \"DecisionTreeClassifier\":\n",
    "        # DecisionTreeClassifier\n",
    "        return DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "    if model_type == \"ExtraTreeClassifier\":\n",
    "        # ExtraTreeClassifier\n",
    "        return ExtraTreeClassifier(random_state=seed)\n",
    "\n",
    "    if model_type == \"LogisticRegression\":\n",
    "        # LogisticRegression\n",
    "        return LogisticRegression(random_state=seed)\n",
    "\n",
    "    if model_type == \"Perceptron\":\n",
    "        return Perceptron(random_state=seed)\n",
    "\n",
    "    if model_type == \"RidgeClassifier\":\n",
    "        return RidgeClassifier(random_state=seed)\n",
    "\n",
    "    if model_type == \"SGDClassifier\":\n",
    "        return SGDClassifier(random_state=seed)\n",
    "\n",
    "    if model_type == \"KNeighborsClassifier\":\n",
    "        return KNeighborsClassifier()\n",
    "\n",
    "    if model_type == \"GaussianProcessClassifier\":\n",
    "        return GaussianProcessClassifier(random_state=seed)\n",
    "\n",
    "    if model_type == \"GaussianNB\":\n",
    "        return GaussianNB()\n",
    "\n",
    "    if model_type == \"AdaBoostClassifier\":\n",
    "        return AdaBoostClassifier(random_state=seed)\n",
    "\n",
    "    if model_type == \"BaggingClassifier\":\n",
    "        return BaggingClassifier(random_state=seed)\n",
    "\n",
    "    if model_type == \"RandomForestClassifier\":\n",
    "        return RandomForestClassifier(random_state=seed)\n",
    "\n",
    "    if model_type == \"GradientBoostingClassifier\":\n",
    "        return GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "    if model_type == \"ExtraTreesClassifier\":\n",
    "        return ExtraTreesClassifier(random_state=seed)\n",
    "    \n",
    "    if model_type == \"MLPClassifier\":\n",
    "        return MLPClassifier(random_state=seed, max_iter=1000)\n",
    "\n",
    "    raise ValueError(\"Invalid model type\")\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, X_test, y_test):\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_session_data(subject_id, session_id):\n",
    "    return df_ckplus_dataset[\n",
    "        (df_ckplus_dataset[\"subject_id\"] == subject_id)\n",
    "        & (df_ckplus_dataset[\"session_id\"] == session_id)\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_subjects(emotion, no_of_subjects):\n",
    "    print(f\"Reading subjects for {emotion}... [no_of_subjects={no_of_subjects}]\")\n",
    "    df_subjects = pd.read_csv(f\"dataset/{emotion}_filtered.csv\")\n",
    "    if no_of_subjects is not None:\n",
    "        df_subjects = df_subjects.head(no_of_subjects)\n",
    "    assert no_of_subjects is None or len(df_subjects) == no_of_subjects\n",
    "    df_subjects = df_subjects[[\"subject_id\", \"session_id\"]]\n",
    "    \n",
    "    return df_subjects\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_data(emotion, no_of_subjects, seed=42):\n",
    "    subjects = get_subjects(emotion=emotion, no_of_subjects=no_of_subjects)\n",
    "\n",
    "    df_neutral_train = pd.DataFrame()\n",
    "    df_neutral_test = pd.DataFrame()\n",
    "    df_emotion_train = pd.DataFrame()\n",
    "    df_emotion_test = pd.DataFrame()\n",
    "\n",
    "    for index, row in subjects.iterrows():\n",
    "        subject_id = row[\"subject_id\"]\n",
    "        session_id = row[\"session_id\"]\n",
    "        subject_data = get_subject_session_data(subject_id, session_id)\n",
    "\n",
    "        neutral_data = subject_data.head(len(subject_data) // 2)\n",
    "        emotion_data = subject_data.tail(len(subject_data) // 2)\n",
    "        \n",
    "        neutral_data = neutral_data.sample(n=3, random_state=seed)\n",
    "        emotion_data = emotion_data.sample(n=3, random_state=seed)\n",
    "\n",
    "        neutral_train = neutral_data.head(2)\n",
    "        neutral_test = neutral_data.tail(1)\n",
    "        \n",
    "        emotion_train = emotion_data.head(2)\n",
    "        emotion_test = emotion_data.tail(1)\n",
    "        \n",
    "        df_neutral_train = pd.concat([df_neutral_train, neutral_train])\n",
    "        df_neutral_test = pd.concat([df_neutral_test, neutral_test])\n",
    "        \n",
    "        df_emotion_train = pd.concat([df_emotion_train, emotion_train])\n",
    "        df_emotion_test = pd.concat([df_emotion_test, emotion_test])\n",
    "        \n",
    "    return df_neutral_train, df_neutral_test, df_emotion_train, df_emotion_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_performance(df_train, df_test, feature_emotions: list, feature_type, model_type, seed):\n",
    "    X_train = get_features_from_df(df_train, feature_emotions, feature_type)\n",
    "    y_train = get_classes_from_df(df_train)\n",
    "\n",
    "    X_test = get_features_from_df(df_test, feature_emotions, feature_type)\n",
    "    y_test = get_classes_from_df(df_test)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # \n",
    "    # encoder = LabelEncoder()\n",
    "    # y_train = encoder.fit_transform(y_train)\n",
    "    # y_test = encoder.transform(y_test) \n",
    "    \n",
    "    model = get_model(model_type, seed)\n",
    "    model = train_model(model, X_train, y_train)\n",
    "\n",
    "    return test_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(\n",
    "    emotion, \n",
    "    model_type,\n",
    "    training_set,\n",
    "    test_set,\n",
    "    feature,\n",
    "    no_of_tests, \n",
    "    seed,\n",
    "    no_of_subjects=None\n",
    "):\n",
    "\n",
    "    print(f\"{emotion}: {training_set}-{test_set} with {feature} using {model_type}\")\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    seeds = np.random.randint(0, 1000, no_of_tests)\n",
    "\n",
    "    scores = np.array([])\n",
    "    for test in range(no_of_tests):\n",
    "        print(f\"Running test #{test+1}/{no_of_tests}\")\n",
    "\n",
    "        df_neutral_train, df_neutral_test, df_emotion_train, df_emotion_test = (\n",
    "            generate_train_test_data(emotion=emotion, seed=seeds[test], no_of_subjects=no_of_subjects)\n",
    "        )\n",
    "        df_combined_train = pd.concat([df_neutral_train, df_emotion_train])\n",
    "        df_combined_test = pd.concat([df_neutral_test, df_emotion_test])\n",
    "\n",
    "        df_train = None\n",
    "        if training_set == \"neutral\":\n",
    "            df_train = df_neutral_train\n",
    "        elif training_set == f\"{emotion}\":\n",
    "            df_train = df_emotion_train\n",
    "        elif training_set == f\"neutral_{emotion}\":\n",
    "            df_train = df_combined_train\n",
    "        assert df_train is not None\n",
    "\n",
    "        df_test = None\n",
    "        if test_set == \"neutral\":\n",
    "            df_test = df_neutral_test\n",
    "        elif test_set == f\"{emotion}\":\n",
    "            df_test = df_emotion_test\n",
    "        elif test_set == f\"neutral_{emotion}\":\n",
    "            df_test = df_combined_test\n",
    "        assert df_test is not None\n",
    "\n",
    "        feature_emotions = None\n",
    "        if feature == \"neutral\":\n",
    "            feature_emotions = [\"neutral\"]\n",
    "        elif feature == f\"{emotion}\":\n",
    "            feature_emotions = [emotion]\n",
    "        elif feature == f\"neutral_{emotion}\":\n",
    "            # feature_emotions = [\"neutral\", emotion]\n",
    "            feature_emotions = [f\"neutral-{emotion}\"]\n",
    "        assert feature_emotions is not None\n",
    "\n",
    "        score = evaluate_performance(\n",
    "            df_train=df_train,\n",
    "            df_test=df_test,\n",
    "            feature_emotions=feature_emotions,\n",
    "            feature_type=\"distance\",\n",
    "            model_type=model_type,\n",
    "            seed=seeds[test],\n",
    "        )\n",
    "\n",
    "        print(\"Score: \", score * 100)\n",
    "        scores = np.append(scores, score)\n",
    "\n",
    "    result = {\n",
    "        \"training_set\": training_set,\n",
    "        \"test_set\": test_set,\n",
    "        \"feature_set\": feature,\n",
    "        \"feature_type\": \"distance\",\n",
    "        \"model_type\": model_type,\n",
    "        \"accuracy\": 100 * scores.mean(),\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change emotions\n",
    "emotions = [\n",
    "    # \"anger\",\n",
    "    # \"disgust\",\n",
    "    # \"fear\",\n",
    "    \"happiness\",\n",
    "    # \"sadness\",\n",
    "    # \"surprise\",\n",
    "]\n",
    "\n",
    "models = [\n",
    "    \"LinearDiscriminantAnalysis\",\n",
    "    # \"LinearSVC\",\n",
    "    \"SVC\",\n",
    "    # \"DecisionTreeClassifier\",\n",
    "    # \"ExtraTreeClassifier\",\n",
    "    \"LogisticRegression\",\n",
    "    # \"Perceptron\",\n",
    "    # \"KNeighborsClassifier\",\n",
    "    # \"GaussianProcessClassifier\",\n",
    "    # \"GaussianNB\",\n",
    "    \"BaggingClassifier\",\n",
    "    \"RandomForestClassifier\",\n",
    "    # \"GradientBoostingClassifier\",\n",
    "    \"ExtraTreesClassifier\",\n",
    "]\n",
    "\n",
    "neutral = \"neutral\"\n",
    "\n",
    "no_of_data = None\n",
    "no_of_tests = 25\n",
    "seed = 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happiness: neutral_happiness-neutral_happiness with neutral using LinearDiscriminantAnalysis\n",
      "Running test #1/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.11111111111111\n",
      "Running test #2/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.22222222222221\n",
      "Running test #3/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  99.44444444444444\n",
      "Running test #4/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.66666666666667\n",
      "Running test #5/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.33333333333333\n",
      "Running test #6/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  99.44444444444444\n",
      "Running test #7/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.88888888888889\n",
      "Running test #8/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.88888888888889\n",
      "Running test #9/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.88888888888889\n",
      "Running test #10/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  99.44444444444444\n",
      "Running test #11/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #12/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.88888888888889\n",
      "Running test #13/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.33333333333333\n",
      "Running test #14/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  99.44444444444444\n",
      "Running test #15/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.66666666666667\n",
      "Running test #16/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.77777777777777\n",
      "Running test #17/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.22222222222221\n",
      "Running test #18/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.88888888888889\n",
      "Running test #19/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.33333333333333\n",
      "Running test #20/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.33333333333333\n",
      "Running test #21/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  99.44444444444444\n",
      "Running test #22/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.22222222222221\n",
      "Running test #23/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.88888888888889\n",
      "Running test #24/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.77777777777777\n",
      "Running test #25/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.88888888888889\n",
      "        training_set           test_set feature_set feature_type  \\\n",
      "0  neutral_happiness  neutral_happiness     neutral     distance   \n",
      "\n",
      "                   model_type   accuracy  \n",
      "0  LinearDiscriminantAnalysis  98.377778  \n",
      "\n",
      "happiness: neutral_happiness-neutral_happiness with happiness using LinearDiscriminantAnalysis\n",
      "Running test #1/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.11111111111111\n",
      "Running test #2/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.66666666666667\n",
      "Running test #3/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.22222222222221\n",
      "Running test #4/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.11111111111111\n",
      "Running test #5/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.33333333333333\n",
      "Running test #6/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.22222222222221\n",
      "Running test #7/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.22222222222221\n",
      "Running test #8/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.33333333333333\n",
      "Running test #9/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.33333333333333\n",
      "Running test #10/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  99.44444444444444\n",
      "Running test #11/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.33333333333333\n",
      "Running test #12/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.88888888888889\n",
      "Running test #13/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.66666666666667\n",
      "Running test #14/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.66666666666667\n",
      "Running test #15/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  94.44444444444444\n",
      "Running test #16/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.11111111111111\n",
      "Running test #17/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  95.55555555555556\n",
      "Running test #18/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.77777777777777\n",
      "Running test #19/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.77777777777777\n",
      "Running test #20/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  95.55555555555556\n",
      "Running test #21/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.66666666666667\n",
      "Running test #22/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  94.44444444444444\n",
      "Running test #23/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  98.33333333333333\n",
      "Running test #24/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  96.11111111111111\n",
      "Running test #25/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  97.77777777777777\n",
      "        training_set           test_set feature_set feature_type  \\\n",
      "0  neutral_happiness  neutral_happiness     neutral     distance   \n",
      "1  neutral_happiness  neutral_happiness   happiness     distance   \n",
      "\n",
      "                   model_type   accuracy  \n",
      "0  LinearDiscriminantAnalysis  98.377778  \n",
      "1  LinearDiscriminantAnalysis  97.044444  \n",
      "\n",
      "happiness: neutral_happiness-neutral_happiness with neutral_happiness using LinearDiscriminantAnalysis\n",
      "Running test #1/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  99.44444444444444\n",
      "Running test #2/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #3/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #4/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #5/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #6/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #7/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #8/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #9/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #10/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #11/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #12/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #13/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #14/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #15/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  99.44444444444444\n",
      "Running test #16/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #17/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #18/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #19/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #20/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #21/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #22/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #23/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #24/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "Running test #25/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  100.0\n",
      "        training_set           test_set        feature_set feature_type  \\\n",
      "0  neutral_happiness  neutral_happiness            neutral     distance   \n",
      "1  neutral_happiness  neutral_happiness          happiness     distance   \n",
      "2  neutral_happiness  neutral_happiness  neutral_happiness     distance   \n",
      "\n",
      "                   model_type   accuracy  \n",
      "0  LinearDiscriminantAnalysis  98.377778  \n",
      "1  LinearDiscriminantAnalysis  97.044444  \n",
      "2  LinearDiscriminantAnalysis  99.955556  \n",
      "\n",
      "happiness: neutral_happiness-neutral_happiness with neutral using SVC\n",
      "Running test #1/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  76.66666666666667\n",
      "Running test #2/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  68.88888888888889\n",
      "Running test #3/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  75.55555555555556\n",
      "Running test #4/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  80.55555555555556\n",
      "Running test #5/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  75.55555555555556\n",
      "Running test #6/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  76.11111111111111\n",
      "Running test #7/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  75.0\n",
      "Running test #8/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  80.0\n",
      "Running test #9/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  77.22222222222223\n",
      "Running test #10/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  80.0\n",
      "Running test #11/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  82.22222222222221\n",
      "Running test #12/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n",
      "Score:  82.77777777777777\n",
      "Running test #13/25\n",
      "Reading subjects for happiness... [no_of_subjects=None]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 177\u001b[0m\n\u001b[0;32m      2\u001b[0m     df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m      3\u001b[0m         columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_set\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_set\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_set\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m     )\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#         # neutral-neutral with neutral\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \n\u001b[0;32m    176\u001b[0m         \u001b[38;5;66;03m# both-both with neutral\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43memotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memotion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mneutral\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43memotion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mneutral\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43memotion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneutral\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43mno_of_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_of_tests\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m         df_results\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(df_results)] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mprint\u001b[39m(df_results)\n",
      "Cell \u001b[1;32mIn[102], line 22\u001b[0m, in \u001b[0;36mrun_test\u001b[1;34m(emotion, model_type, training_set, test_set, feature, no_of_tests, seed, no_of_subjects)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(no_of_tests):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning test #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mno_of_tests\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     df_neutral_train, df_neutral_test, df_emotion_train, df_emotion_test \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 22\u001b[0m         \u001b[43mgenerate_train_test_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43memotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memotion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_of_subjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_of_subjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     )\n\u001b[0;32m     24\u001b[0m     df_combined_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_neutral_train, df_emotion_train])\n\u001b[0;32m     25\u001b[0m     df_combined_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_neutral_test, df_emotion_test])\n",
      "Cell \u001b[1;32mIn[100], line 27\u001b[0m, in \u001b[0;36mgenerate_train_test_data\u001b[1;34m(emotion, no_of_subjects, seed)\u001b[0m\n\u001b[0;32m     24\u001b[0m emotion_test \u001b[38;5;241m=\u001b[39m emotion_data\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m df_neutral_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_neutral_train, neutral_train])\n\u001b[1;32m---> 27\u001b[0m df_neutral_test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_neutral_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneutral_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m df_emotion_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_emotion_train, emotion_train])\n\u001b[0;32m     30\u001b[0m df_emotion_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_emotion_test, emotion_test])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:385\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    372\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[1;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\concat.py:242\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    240\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\concat.py:613\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, copy)\u001b[0m\n\u001b[0;32m    610\u001b[0m     concat_values \u001b[38;5;241m=\u001b[39m ensure_block_shape(concat_values, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 613\u001b[0m     concat_values \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat_values\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\dtypes\\concat.py:117\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m     target_dtype \u001b[38;5;241m=\u001b[39m np_find_common_type(\u001b[38;5;241m*\u001b[39mdtypes)\n\u001b[1;32m--> 117\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kinds \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# GH#39817 cast to object instead of casting bools to numeric\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for emotion in emotions:\n",
    "    df_results = pd.DataFrame(\n",
    "        columns=[\"training_set\", \"test_set\", \"feature_set\", \"feature_type\", \"model_type\", \"accuracy\"]\n",
    "    )\n",
    "\n",
    "    for model_type in models:\n",
    "\n",
    "#         # neutral-neutral with neutral\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=neutral,\n",
    "#             test_set=neutral,\n",
    "#             feature=neutral,\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # neutral-neutral with emotion\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=neutral,\n",
    "#             test_set=neutral,\n",
    "#             feature=emotion,\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # neutral-neutral with both\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=neutral,\n",
    "#             test_set=neutral,\n",
    "#             feature=f\"{neutral}_{emotion}\",\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "\n",
    "#         # neutral-emotion with neutral\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=neutral,\n",
    "#             test_set=emotion,\n",
    "#             feature=neutral,\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # neutral-emotion with emotion\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=neutral,\n",
    "#             test_set=emotion,\n",
    "#             feature=emotion,\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # neutral-emotion with both\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=neutral,\n",
    "#             test_set=emotion,\n",
    "#             feature=f\"{neutral}_{emotion}\",\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # emotion-neutral with neutral\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=emotion,\n",
    "#             test_set=neutral,\n",
    "#             feature=neutral,\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # emotion-neutral with emotion\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=emotion,\n",
    "#             test_set=neutral,\n",
    "#             feature=emotion,\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # emotion-neutral with both\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=emotion,\n",
    "#             test_set=neutral,\n",
    "#             feature=f\"{neutral}_{emotion}\",\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # emotion-emotion with neutral\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=emotion,\n",
    "#             test_set=emotion,\n",
    "#             feature=neutral,\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # emotion-emotion with emotion\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=emotion,\n",
    "#             test_set=emotion,\n",
    "#             feature=emotion,\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "# \n",
    "#         # emotion-emotion with both\n",
    "#         result = run_test(\n",
    "#             emotion=emotion,\n",
    "#             model_type=model_type,\n",
    "#             training_set=emotion,\n",
    "#             test_set=emotion,\n",
    "#             feature=f\"{neutral}_{emotion}\",\n",
    "#             no_of_tests=no_of_tests,\n",
    "#             seed=seed,\n",
    "#         )\n",
    "#         df_results.loc[len(df_results)] = result\n",
    "#         print(df_results)\n",
    "#         print()\n",
    "\n",
    "        # both-both with neutral\n",
    "        result = run_test(\n",
    "            emotion=emotion,\n",
    "            model_type=model_type,\n",
    "            training_set=f\"{neutral}_{emotion}\",\n",
    "            test_set=f\"{neutral}_{emotion}\",\n",
    "            feature=neutral,\n",
    "            no_of_tests=no_of_tests,\n",
    "            seed=seed,\n",
    "        )\n",
    "        df_results.loc[len(df_results)] = result\n",
    "        print(df_results)\n",
    "        print()\n",
    "\n",
    "        # emotion-neutral with emotion\n",
    "        result = run_test(\n",
    "            emotion=emotion,\n",
    "            model_type=model_type,\n",
    "            training_set=f\"{neutral}_{emotion}\",\n",
    "            test_set=f\"{neutral}_{emotion}\",\n",
    "            feature=emotion,\n",
    "            no_of_tests=no_of_tests,\n",
    "            seed=seed,\n",
    "        )\n",
    "        df_results.loc[len(df_results)] = result\n",
    "        print(df_results)\n",
    "        print()\n",
    "\n",
    "        # emotion-neutral with both\n",
    "        result = run_test(\n",
    "            emotion=emotion,\n",
    "            model_type=model_type,\n",
    "            training_set=f\"{neutral}_{emotion}\",\n",
    "            test_set=f\"{neutral}_{emotion}\",\n",
    "            feature=f\"{neutral}_{emotion}\",\n",
    "            no_of_tests=no_of_tests,\n",
    "            seed=seed,\n",
    "        )\n",
    "        df_results.loc[len(df_results)] = result\n",
    "        print(df_results)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        df_results.to_csv(f\"results/{emotion}_temp.csv\")\n",
    "        \n",
    "    \n",
    "    df_results.to_csv(f\"results/{emotion}.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
